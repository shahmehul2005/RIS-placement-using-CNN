{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMvLOhXYsCxw8FLllVhePz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahmehul2005/RIS-placement-using-CNN/blob/main/collection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5qLf_IFHGca"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcx65A3ktQ_x",
        "outputId": "56fe0bea-86c3-40c5-b676-0d5a1e561304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l /content/drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkagievEtrGo",
        "outputId": "03f7acca-1b56-4748-a713-320ec746b542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: /content/drive/MyDrive/exported_data: No such file or directory\n",
            "total 11479007\n",
            "drwx------ 2 root root        4096 Jul 12 12:18 'Colab Notebooks'\n",
            "lrw------- 1 root root           0 Jul 19 13:43  exported_data -> /content/drive/.shortcut-targets-by-id/1YJLMkIacvVePd6oPzzYNiBMIwveylN_D/exported_data\n",
            "-rw------- 1 root root 11754498403 Jul 20 07:23  uavid.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/drive/MyDrive/uavid.zip"
      ],
      "metadata": {
        "id": "6195Z-xxtywC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "# Set your image directory path\n",
        "image_dir = \"/content/uavid_val\"  # 👈 Update this path\n",
        "\n",
        "# Get all image files\n",
        "image_files = glob.glob(f\"{image_dir}/**/*.*\", recursive=True)\n",
        "\n",
        "# Filter for image extensions\n",
        "valid_extensions = ('.jpg', '.jpeg', '.png', '.gif', '.bmp')\n",
        "image_files = [f for f in image_files if f.lower().endswith(valid_extensions)]\n",
        "\n",
        "print(f\"Total images: {len(image_files)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NPlHG8pxmY6",
        "outputId": "1a9bbae0-131a-445c-c7da-aec13dfcaf24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: 140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEzj61X19Ndy"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "\n",
        "\n",
        "dataset_base_path = '/content/uavid_train'\n",
        "output_base_path = '/content/uavid_yolo_labels'\n",
        "\n",
        "# List of sequence folders to process\n",
        "sequences_to_process = 'seq1'\n",
        "sequences = [s.strip() for s in sequences_to_process.split(',')]\n",
        "\n",
        "# UAVid Color Map\n",
        "UAVID_COLOR_MAP = {\n",
        "    'Building': (128, 0, 0),\n",
        "    'Road': (128, 64, 128),\n",
        "    'Tree': (0, 128, 0),\n",
        "    'Low vegetation': (128, 128, 0),\n",
        "    'Moving car': (64, 0, 128),\n",
        "    'Static car': (192, 0, 192),\n",
        "    'Human': (64, 64, 0),\n",
        "    'Background clutter': (0, 0, 0)\n",
        "}\n",
        "\n",
        "# Classes for instance segmentation\n",
        "INSTANCE_CLASSES = ['Building', 'Tree', 'Low vegetation']\n",
        "CLASS_ID_MAP = {cls: idx for idx, cls in enumerate(INSTANCE_CLASSES)}\n",
        "\n",
        "def apply_watershed_to_class(class_mask, original_image):\n",
        "    \"\"\"Apply watershed algorithm to a binary class mask\"\"\"\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    opening = cv2.morphologyEx(class_mask, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
        "\n",
        "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
        "    _, sure_fg = cv2.threshold(dist_transform, 0.5 * dist_transform.max(), 255, 0)\n",
        "\n",
        "    sure_fg = np.uint8(sure_fg)\n",
        "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
        "\n",
        "    _, markers = cv2.connectedComponents(sure_fg)\n",
        "    markers = markers + 1\n",
        "    markers[unknown == 255] = 0\n",
        "\n",
        "    markers = cv2.watershed(original_image, markers)\n",
        "    markers[markers == 1] = 0\n",
        "    markers[markers == -1] = 0\n",
        "\n",
        "    return markers\n",
        "\n",
        "def get_yolo_annotations(semantic_img_rgb, original_img):\n",
        "    \"\"\"Generate YOLO format annotations from semantic segmentation\"\"\"\n",
        "    annotations = []\n",
        "    height, width, _ = original_img.shape\n",
        "\n",
        "    for class_name in INSTANCE_CLASSES:\n",
        "        color = UAVID_COLOR_MAP[class_name]\n",
        "        mask = cv2.inRange(semantic_img_rgb, color, color)\n",
        "\n",
        "        if np.any(mask):\n",
        "            instance_labels = apply_watershed_to_class(mask, original_img)\n",
        "            unique_ids = np.unique(instance_labels)\n",
        "            unique_ids = unique_ids[unique_ids != 0]\n",
        "\n",
        "            for uid in unique_ids:\n",
        "                instance_mask = (instance_labels == uid)\n",
        "                if np.count_nonzero(instance_mask) < 10:  # Skip small instances\n",
        "                    continue\n",
        "\n",
        "                coords = np.where(instance_mask)\n",
        "                y_min, y_max = np.min(coords[0]), np.max(coords[0])\n",
        "                x_min, x_max = np.min(coords[1]), np.max(coords[1])\n",
        "\n",
        "                # Calculate YOLO format (normalized center coordinates and dimensions)\n",
        "                center_x = (x_min + x_max) / 2.0 / width\n",
        "                center_y = (y_min + y_max) / 2.0 / height\n",
        "                bbox_width = (x_max - x_min) / width\n",
        "                bbox_height = (y_max - y_min) / height\n",
        "\n",
        "                # Clip values to [0,1] range\n",
        "                center_x = np.clip(center_x, 0, 1)\n",
        "                center_y = np.clip(center_y, 0, 1)\n",
        "                bbox_width = np.clip(bbox_width, 0, 1)\n",
        "                bbox_height = np.clip(bbox_height, 0, 1)\n",
        "\n",
        "                class_id = CLASS_ID_MAP[class_name]\n",
        "                annotations.append((class_id, center_x, center_y, bbox_width, bbox_height))\n",
        "\n",
        "    return annotations\n",
        "\n",
        "print(\"Starting conversion to YOLO format...\")\n",
        "print(f\"Processing sequences: {sequences}\")\n",
        "print(f\"Input path: {dataset_base_path}\")\n",
        "print(f\"Output path: {output_base_path}\")\n",
        "\n",
        "visualization_data = []\n",
        "\n",
        "for seq in sequences:\n",
        "    seq_path = os.path.join(dataset_base_path, seq)\n",
        "    image_folder = os.path.join(seq_path, 'Images')\n",
        "    label_folder = os.path.join(seq_path, 'Labels')\n",
        "    output_seq_path = os.path.join(output_base_path, seq, 'labels')\n",
        "    os.makedirs(output_seq_path, exist_ok=True)\n",
        "\n",
        "    if not os.path.isdir(image_folder) or not os.path.isdir(label_folder):\n",
        "        print(f\"Warning: Missing folders in {seq_path}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nProcessing sequence: {seq}\")\n",
        "    label_files = sorted([f for f in os.listdir(label_folder) if f.endswith('.png')])\n",
        "\n",
        "    for i, label_file in enumerate(label_files):\n",
        "        label_path = os.path.join(label_folder, label_file)\n",
        "        image_path = os.path.join(image_folder, label_file.replace('.png', '.jpg'))\n",
        "\n",
        "        if not os.path.exists(image_path):\n",
        "            image_path = image_path.replace('.jpg', '.png')\n",
        "            if not os.path.exists(image_path):\n",
        "                print(f\"  - Image not found for {label_file}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "        # Read and process images\n",
        "        semantic_img = cv2.imread(label_path)\n",
        "        if semantic_img is None:\n",
        "            print(f\"  - Could not read semantic label: {label_path}\")\n",
        "            continue\n",
        "\n",
        "        semantic_img_rgb = cv2.cvtColor(semantic_img, cv2.COLOR_BGR2RGB)\n",
        "        original_img = cv2.imread(image_path)\n",
        "        if original_img is None:\n",
        "            print(f\"  - Could not read image: {image_path}\")\n",
        "            continue\n",
        "\n",
        "        # Get YOLO annotations\n",
        "        annotations = get_yolo_annotations(semantic_img_rgb, original_img)\n",
        "\n",
        "        # Save to text file\n",
        "        txt_filename = label_file.replace('.png', '.txt')\n",
        "        txt_path = os.path.join(output_seq_path, txt_filename)\n",
        "        with open(txt_path, 'w') as f:\n",
        "            for ann in annotations:\n",
        "                f.write(f\"{ann[0]} {ann[1]:.6f} {ann[2]:.6f} {ann[3]:.6f} {ann[4]:.6f}\\n\")\n",
        "\n",
        "        # Store first 3 for visualization\n",
        "        if i < 3:\n",
        "            visualization_data.append({\n",
        "                'image_path': image_path,\n",
        "                'txt_path': txt_path,\n",
        "                'semantic_path': label_path\n",
        "            })\n",
        "\n",
        "print(\"\\nConversion complete!\")\n",
        "\n",
        "# Visualization\n",
        "if visualization_data:\n",
        "    print(\"\\nVisualizing results...\")\n",
        "    for data in visualization_data:\n",
        "        img = cv2.imread(data['image_path'])\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        height, width, _ = img.shape\n",
        "\n",
        "        # Read annotations\n",
        "        with open(data['txt_path']) as f:\n",
        "            annotations = []\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) == 5:\n",
        "                    class_id, cx, cy, w, h = map(float, parts)\n",
        "                    annotations.append((int(class_id), cx, cy, w, h))\n",
        "\n",
        "        # Draw bounding boxes\n",
        "        img_with_boxes = img_rgb.copy()\n",
        "        for ann in annotations:\n",
        "            class_id, cx, cy, w, h = ann\n",
        "            # Convert from normalized to pixel coordinates\n",
        "            x_center = int(cx * width)\n",
        "            y_center = int(cy * height)\n",
        "            bbox_width = int(w * width)\n",
        "            bbox_height = int(h * height)\n",
        "\n",
        "            x_min = max(0, x_center - bbox_width // 2)\n",
        "            y_min = max(0, y_center - bbox_height // 2)\n",
        "            x_max = min(width, x_center + bbox_width // 2)\n",
        "            y_max = min(height, y_center + bbox_height // 2)\n",
        "\n",
        "            # Draw rectangle and label\n",
        "            color = (0, 255, 0)  # Green\n",
        "            cv2.rectangle(img_with_boxes, (x_min, y_min), (x_max, y_max), color, 2)\n",
        "            class_name = INSTANCE_CLASSES[class_id]\n",
        "            cv2.putText(img_with_boxes, class_name, (x_min, y_min - 10),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
        "\n",
        "        # Display results\n",
        "        fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
        "        ax[0].imshow(img_rgb)\n",
        "        ax[0].set_title('Original Image')\n",
        "        ax[0].axis('off')\n",
        "\n",
        "        ax[1].imshow(img_with_boxes)\n",
        "        ax[1].set_title('YOLO Annotations')\n",
        "        ax[1].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"\\nNo files processed for visualization\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/uavid_yolo_labels2 /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "vkUCq8imUCLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##"
      ],
      "metadata": {
        "id": "pd8ucmFcHcNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()  # Upload the downloaded `kaggle.json`\n"
      ],
      "metadata": {
        "id": "ym0hX66xkG7F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "717e1a16-6c8e-4976-90ad-47ceed97b79b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6c831839-2e1d-4ad1-b461-f52de6c6913f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6c831839-2e1d-4ad1-b461-f52de6c6913f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle (1).json to kaggle (1).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle (1).json': b'{\"username\":\"shahmehul5002\",\"key\":\"9b6639e7976cd03819b326ab5c16a2f8\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle  # Install Kaggle API\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json  # Set correct permissions"
      ],
      "metadata": {
        "id": "WpBMUOwfUODw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download kushagrapandya/visdrone-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lEfELXtUZLK",
        "outputId": "fd210ae9-6873-4685-aa8c-5f83802d4100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/kushagrapandya/visdrone-dataset\n",
            "License(s): GNU Affero General Public License 3.0\n",
            "Downloading visdrone-dataset.zip to /content\n",
            "100% 2.09G/2.10G [00:24<00:00, 242MB/s]\n",
            "100% 2.10G/2.10G [00:24<00:00, 90.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uY5vLkUV_PrY",
        "outputId": "53d95e77-3c04-4c50-bca5-86b7034466ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List shared folders\n",
        "!ls -l \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nu-wl8vmjcW",
        "outputId": "cdf603c8-8a87-4232-cfae-adeb7b401e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: /content/drive/MyDrive/exported_data: No such file or directory\n",
            "ls: /content/drive/MyDrive/uavid_yolo_labels: No such file or directory\n",
            "total 96149\n",
            "-rw------- 1 root root 39478065 Jul 11 11:50  abc.tif\n",
            "drwx------ 2 root root     4096 Jul  5 09:09 'Colab Notebooks'\n",
            "-rw------- 1 root root 52079139 Jul 12 05:35  drone_deploy.pt\n",
            "lrw------- 1 root root        0 Jul 20 06:54  exported_data -> /content/drive/.shortcut-targets-by-id/1YJLMkIacvVePd6oPzzYNiBMIwveylN_D/exported_data\n",
            "-rw------- 1 root root  6889997 Jul 12 05:40  P0054.png\n",
            "lrw------- 1 root root        0 Jul 24 06:32  uavid_yolo_labels -> /content/drive/.shortcut-targets-by-id/1rl-WOOOuvuvXmciZUPLst2InKEsQItXg/uavid_yolo_labels\n",
            "drwx------ 2 root root     4096 Jul  9 12:40  yolo_training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/MyDrive/uavid_yolo_labels\" \"/content/\""
      ],
      "metadata": {
        "id": "mw34tEAfnP1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/MyDrive/yolo_training/uavid.zip\" \"/content/\""
      ],
      "metadata": {
        "id": "gP-r_iglprR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q uavid.zip"
      ],
      "metadata": {
        "id": "vLlG6NuhrIXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ7MMIpRrMXA",
        "outputId": "5c6e05c4-a55d-452a-970a-7777932df447",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.169-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.16.0)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.7.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.7.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.169-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.169 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Config\n",
        "image_dir = \"/content/uavid_train/seq1/Images\"      # Original image directory\n",
        "label_dir = \"/content/uavid_yolo_labels/seq1/labels\"      # Original label directory\n",
        "dataset_path = \"my_dataset\"            # Output directory\n",
        "val_ratio = 0.2                        # 80% train, 20% validation\n",
        "\n",
        "# Create folders\n",
        "os.makedirs(f\"{dataset_path}/images/train\", exist_ok=True)\n",
        "os.makedirs(f\"{dataset_path}/images/val\", exist_ok=True)\n",
        "os.makedirs(f\"{dataset_path}/labels/train\", exist_ok=True)\n",
        "os.makedirs(f\"{dataset_path}/labels/val\", exist_ok=True)\n",
        "\n",
        "# Get image filenames (without extensions)\n",
        "image_files = [f.split('.')[0] for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "image_files_train, image_files_val = train_test_split(image_files, test_size=val_ratio, random_state=42)\n",
        "\n",
        "# Helper function to copy files\n",
        "def copy_files(filenames, source_dir, dest_dir_img, dest_dir_label, ext=\".png\"):\n",
        "    for f in filenames:\n",
        "        # Copy image\n",
        "        shutil.copy2(\n",
        "            os.path.join(source_dir, f + ext),\n",
        "            os.path.join(dest_dir_img, f + ext)\n",
        "        )\n",
        "        # Copy label\n",
        "        label_file = f + \".txt\"\n",
        "        shutil.copy2(\n",
        "            os.path.join(label_dir, label_file),\n",
        "            os.path.join(dest_dir_label, label_file)\n",
        "        )\n",
        "\n",
        "# Copy train/val data\n",
        "copy_files(image_files_train, image_dir, f\"{dataset_path}/images/train\", f\"{dataset_path}/labels/train\")\n",
        "copy_files(image_files_val, image_dir, f\"{dataset_path}/images/val\", f\"{dataset_path}/labels/val\")\n",
        "\n",
        "print(f\"Train: {len(image_files_train)} images | Val: {len(image_files_val)} images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hm02gRPirRrn",
        "outputId": "aa3fc0e9-517a-4a31-ca99-0d0ccbffdc55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 480 images | Val: 120 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/visdrone-dataset.zip"
      ],
      "metadata": {
        "id": "oVnqO0icXV1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --- STEP 1: TRAIN THE TEACHER MODEL ---\n",
        "print(\"--- Starting Teacher Model Training ---\")\n",
        "\n",
        "# Initialize a YOLO model (using pre-trained weights)\n",
        "teacher_model = YOLO(TEACHER_MODEL_PATH)\n",
        "\n",
        "# Train the teacher model on the labeled dataset\n",
        "teacher_model.train(\n",
        "    data=LABELED_DATA_YAML,\n",
        "    epochs=TEACHER_EPOCHS,\n",
        "    imgsz=TEACHER_IMG_SIZE,\n",
        "    batch=TEACHER_BATCH_SIZE,\n",
        "    project=TEACHER_PROJECT_NAME,\n",
        "    name='teacher_run',\n",
        "    patience=20\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uiw5dsdtrtUm",
        "outputId": "4f382b88-0c07-4ba0-b59d-522a53b846de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Teacher Model Training ---\n",
            "Ultralytics 8.3.169 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/my_dataset/student_data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1280, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=teacher_run9, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=teacher_training, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=teacher_training/teacher_run9, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 27.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model summary: 129 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 82.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 209.1±12.6 MB/s, size: 15052.6 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/my_dataset/labels/train... 480 images, 0 backgrounds, 0 corrupt: 100%|██████████| 480/480 [00:30<00:00, 15.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/my_dataset/labels/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 183.0±41.4 MB/s, size: 14762.8 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/my_dataset/labels/val... 120 images, 0 backgrounds, 0 corrupt: 100%|██████████| 120/120 [00:11<00:00, 10.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/my_dataset/labels/val.cache\n",
            "Plotting labels to teacher_training/teacher_run9/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 1280 train, 1280 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mteacher_training/teacher_run9\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/50      5.13G      2.163      3.336      2.035        175       1280: 100%|██████████| 60/60 [02:14<00:00,  2.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:22<00:00,  2.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175     0.0292       0.39     0.0837     0.0328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/50      5.58G      2.011      2.836      1.862        263       1280: 100%|██████████| 60/60 [02:23<00:00,  2.39s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:23<00:00,  2.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.226      0.196      0.129     0.0514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/50      6.03G      1.958      2.673      1.836        197       1280: 100%|██████████| 60/60 [02:20<00:00,  2.34s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:24<00:00,  3.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.215      0.236      0.146     0.0636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/50      6.05G      1.944      2.595      1.816        309       1280: 100%|██████████| 60/60 [02:16<00:00,  2.28s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:22<00:00,  2.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.236      0.244      0.149     0.0602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/50      6.06G      1.949      2.483      1.792        255       1280: 100%|██████████| 60/60 [02:18<00:00,  2.31s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:22<00:00,  2.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.286      0.242      0.175     0.0725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/50      6.59G      1.884      2.395      1.755        239       1280: 100%|██████████| 60/60 [02:13<00:00,  2.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:22<00:00,  2.76s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.317      0.267      0.215     0.0956\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/50      6.61G      1.882      2.357       1.74        264       1280: 100%|██████████| 60/60 [02:14<00:00,  2.25s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:23<00:00,  2.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.303       0.26      0.174      0.071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/50      6.62G      1.863      2.293      1.723        350       1280: 100%|██████████| 60/60 [02:12<00:00,  2.20s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:18<00:00,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.364      0.288      0.246      0.113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/50      6.64G      1.841      2.262      1.703        217       1280: 100%|██████████| 60/60 [02:14<00:00,  2.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:19<00:00,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.339       0.29      0.239       0.11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/50      6.66G      1.822      2.218      1.692        273       1280: 100%|██████████| 60/60 [02:13<00:00,  2.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:19<00:00,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.364        0.3      0.253      0.118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/50      6.67G        1.8      2.158      1.676        240       1280: 100%|██████████| 60/60 [02:13<00:00,  2.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:18<00:00,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.355        0.3      0.263      0.125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/50      7.26G      1.755      2.094      1.644        283       1280: 100%|██████████| 60/60 [02:14<00:00,  2.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:19<00:00,  2.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175       0.39      0.324      0.285      0.138\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/50      7.28G      1.737      2.072      1.646        250       1280: 100%|██████████| 60/60 [02:14<00:00,  2.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:19<00:00,  2.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.418      0.318      0.282      0.138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/50      7.29G      1.741      2.015      1.626        277       1280: 100%|██████████| 60/60 [02:14<00:00,  2.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:18<00:00,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.376      0.321      0.282       0.14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/50      7.31G      1.716       1.99      1.618        197       1280: 100%|██████████| 60/60 [02:12<00:00,  2.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:18<00:00,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.424      0.321        0.3      0.146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/50      8.02G      1.695      1.932      1.589        259       1280: 100%|██████████| 60/60 [02:11<00:00,  2.19s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:17<00:00,  2.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.417      0.336      0.309       0.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/50      5.12G      1.687      1.945      1.598        292       1280: 100%|██████████| 60/60 [02:16<00:00,  2.28s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:18<00:00,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.451      0.345      0.327      0.162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/50      5.61G      1.667      1.893      1.575        222       1280: 100%|██████████| 60/60 [02:13<00:00,  2.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:18<00:00,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.427      0.349      0.328      0.162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/50      5.61G      1.658      1.894      1.571        247       1280: 100%|██████████| 60/60 [02:12<00:00,  2.21s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:19<00:00,  2.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.421       0.35      0.316      0.159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/50      5.61G      1.627       1.85       1.56        211       1280: 100%|██████████| 60/60 [02:13<00:00,  2.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:19<00:00,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.478       0.34      0.326      0.163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/50      5.61G      1.648      1.831      1.559        219       1280: 100%|██████████| 60/60 [02:15<00:00,  2.26s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:18<00:00,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.461      0.346      0.335      0.175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/50      5.61G      1.618      1.793      1.539        217       1280: 100%|██████████| 60/60 [02:14<00:00,  2.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:18<00:00,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175       0.47      0.361      0.352      0.184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/50      6.11G      1.618      1.747       1.53        254       1280: 100%|██████████| 60/60 [02:14<00:00,  2.25s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:19<00:00,  2.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.441      0.361      0.331      0.169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/50      6.13G      1.611      1.716      1.508        270       1280: 100%|██████████| 60/60 [02:14<00:00,  2.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:18<00:00,  2.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.484      0.358      0.356      0.183\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/50      6.14G      1.587      1.702      1.505        221       1280: 100%|██████████| 60/60 [02:15<00:00,  2.26s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:17<00:00,  2.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.472      0.343      0.338      0.169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/50      6.16G       1.55      1.656      1.484        323       1280: 100%|██████████| 60/60 [02:12<00:00,  2.21s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:18<00:00,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.505      0.395       0.38      0.199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/50      6.18G      1.561       1.66      1.498        180       1280: 100%|██████████| 60/60 [02:15<00:00,  2.25s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:18<00:00,  2.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.476      0.399      0.363      0.185\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/50       6.2G      1.541      1.646      1.479        212       1280: 100%|██████████| 60/60 [02:16<00:00,  2.27s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:19<00:00,  2.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175       0.49      0.364      0.353      0.186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/50      6.21G      1.545      1.607      1.482        312       1280: 100%|██████████| 60/60 [02:16<00:00,  2.28s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:18<00:00,  2.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.504      0.378      0.367       0.19\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/50      6.23G      1.517      1.579      1.467        207       1280: 100%|██████████| 60/60 [02:13<00:00,  2.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:19<00:00,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.518        0.4      0.396       0.21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      31/50      6.25G      1.491      1.545      1.442        257       1280: 100%|██████████| 60/60 [02:13<00:00,  2.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:18<00:00,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.545       0.41      0.404      0.215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      32/50      6.27G      1.489      1.517      1.437        239       1280: 100%|██████████| 60/60 [02:15<00:00,  2.26s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:17<00:00,  2.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.533      0.411      0.407      0.217\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      33/50      6.83G      1.527      1.537      1.443        377       1280: 100%|██████████| 60/60 [02:14<00:00,  2.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:19<00:00,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.563      0.397      0.413      0.218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      34/50      6.85G      1.473      1.478      1.416        257       1280: 100%|██████████| 60/60 [02:15<00:00,  2.25s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:19<00:00,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.538      0.416      0.423      0.227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      35/50      6.86G      1.454      1.455      1.414        234       1280: 100%|██████████| 60/60 [02:19<00:00,  2.33s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:19<00:00,  2.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.553      0.411      0.414      0.224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      36/50      6.88G      1.429      1.417      1.393        209       1280: 100%|██████████| 60/60 [02:18<00:00,  2.31s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:21<00:00,  2.66s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.551      0.417      0.417      0.231\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      37/50      7.52G      1.428      1.418      1.396        338       1280: 100%|██████████| 60/60 [02:17<00:00,  2.28s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:19<00:00,  2.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.544       0.43      0.436      0.236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      38/50      5.03G      1.429      1.403       1.38        184       1280: 100%|██████████| 60/60 [02:18<00:00,  2.32s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:20<00:00,  2.51s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.577      0.412      0.432      0.234\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      39/50      6.29G      1.416      1.363       1.37        188       1280: 100%|██████████| 60/60 [02:20<00:00,  2.34s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:21<00:00,  2.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.589      0.431      0.448      0.243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      40/50      6.29G      1.403      1.361       1.37        318       1280: 100%|██████████| 60/60 [02:17<00:00,  2.29s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:22<00:00,  2.76s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.592      0.415      0.438      0.239\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      41/50      6.29G      1.508       1.56       1.46        114       1280: 100%|██████████| 60/60 [02:13<00:00,  2.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:20<00:00,  2.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.573      0.413      0.426      0.226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      42/50      6.29G      1.437      1.488      1.418        104       1280: 100%|██████████| 60/60 [02:04<00:00,  2.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:20<00:00,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.532      0.429      0.416      0.227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      43/50      6.29G      1.424      1.406      1.398        152       1280: 100%|██████████| 60/60 [02:05<00:00,  2.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:21<00:00,  2.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.563      0.419      0.424      0.232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      44/50      6.29G      1.383      1.345      1.377        139       1280: 100%|██████████| 60/60 [02:02<00:00,  2.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:21<00:00,  2.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.573      0.429      0.447      0.248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      45/50      6.29G      1.361      1.306       1.36         97       1280: 100%|██████████| 60/60 [02:02<00:00,  2.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:21<00:00,  2.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.586       0.44      0.458      0.254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      46/50      6.29G      1.338       1.28       1.35        161       1280: 100%|██████████| 60/60 [02:00<00:00,  2.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:21<00:00,  2.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175       0.61      0.439      0.461      0.256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      47/50      6.29G      1.344      1.279      1.354        128       1280: 100%|██████████| 60/60 [02:01<00:00,  2.02s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:21<00:00,  2.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.609      0.446      0.467      0.261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      48/50      6.29G       1.33      1.257      1.344        150       1280: 100%|██████████| 60/60 [02:04<00:00,  2.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:20<00:00,  2.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.625      0.421      0.465      0.258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      49/50       6.3G      1.323      1.244      1.339        123       1280: 100%|██████████| 60/60 [02:04<00:00,  2.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:21<00:00,  2.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.609       0.45      0.472      0.261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      50/50      6.32G      1.305      1.219      1.327         90       1280: 100%|██████████| 60/60 [02:00<00:00,  2.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:20<00:00,  2.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.631      0.439      0.476      0.263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "50 epochs completed in 2.143 hours.\n",
            "Optimizer stripped from teacher_training/teacher_run9/weights/last.pt, 6.3MB\n",
            "Optimizer stripped from teacher_training/teacher_run9/weights/best.pt, 6.3MB\n",
            "\n",
            "Validating teacher_training/teacher_run9/weights/best.pt...\n",
            "Ultralytics 8.3.169 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:32<00:00,  4.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        120       2175      0.629      0.438      0.475      0.263\n",
            "              building        119        562      0.679      0.537       0.57      0.338\n",
            "                  tree        120        896      0.615      0.432      0.471      0.243\n",
            "        low vegetation        120        717      0.592      0.346      0.385      0.207\n",
            "Speed: 0.6ms preprocess, 6.1ms inference, 0.0ms loss, 5.7ms postprocess per image\n",
            "Results saved to \u001b[1mteacher_training/teacher_run9\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'teacher_project/teacher_run/weights/best.pt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-20-1469230489.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m# 3. Export model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0mdrive_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrive_export_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'teacher_best.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_teacher_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrive_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- Teacher Model Exported to Google Drive ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'teacher_project/teacher_run/weights/best.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# 1. Define paths\n",
        "TEACHER_PROJECT_NAME = \"teacher_training\"  # Replace with your actual project name\n",
        "best_teacher_weights = os.path.join(TEACHER_PROJECT_NAME, 'teacher_run9/weights/best.pt')\n",
        "\n",
        "# 2. Configure export directory (customize this)\n",
        "drive_export_path = '/content/drive/MyDrive/models/yolo_teacher'\n",
        "os.makedirs(drive_export_path, exist_ok=True)\n",
        "\n",
        "# 3. Export model\n",
        "drive_model_path = os.path.join(drive_export_path, 'teacher_best.pt')\n",
        "shutil.copy(best_teacher_weights, drive_model_path)\n",
        "\n",
        "print(\"--- Teacher Model Exported to Google Drive ---\")\n",
        "print(f\"Source: {best_teacher_weights}\")\n",
        "print(f\"Destination: {drive_model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEp8jNYc-Auk",
        "outputId": "9029d3a2-2ea5-4ee6-8cd0-de104353fce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Teacher Model Exported to Google Drive ---\n",
            "Source: teacher_training/teacher_run9/weights/best.pt\n",
            "Destination: /content/drive/MyDrive/models/yolo_teacher/teacher_best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##"
      ],
      "metadata": {
        "id": "PzhXMoJMIGeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()  # Upload the downloaded `kaggle.json`\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "Mi65kFqlz7Ko",
        "outputId": "2e11f979-fa4c-4aaa-aea6-14e7aae61b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-252068b5-8ff4-4491-9ad6-89fb7d9e884b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-252068b5-8ff4-4491-9ad6-89fb7d9e884b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle (1).json to kaggle (1).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle (1).json': b'{\"username\":\"shahmehul5002\",\"key\":\"9b6639e7976cd03819b326ab5c16a2f8\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle  # Install Kaggle API\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json  # Set correct permissions"
      ],
      "metadata": {
        "id": "mwwlbYXh0OVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download kushagrapandya/visdrone-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwDzNS6K0PAo",
        "outputId": "c9ea38b7-df44-4a95-d9dd-3708b0957f79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/kushagrapandya/visdrone-dataset\n",
            "License(s): GNU Affero General Public License 3.0\n",
            "Downloading visdrone-dataset.zip to /content\n",
            " 99% 2.07G/2.10G [00:12<00:00, 169MB/s]\n",
            "100% 2.10G/2.10G [00:12<00:00, 178MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILt5OwNg0SNb",
        "outputId": "008f6767-72c3-4fac-ec0e-ef63668c5175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List shared folders\n",
        "!ls -l \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu0dlbGK0UQZ",
        "outputId": "f490289b-f73f-49f7-f8d8-364f218afc02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: /content/drive/MyDrive/uavid_yolo_labels: No such file or directory\n",
            "total 11485175\n",
            "drwx------ 2 root root        4096 Jul 15 03:30 'Colab Notebooks'\n",
            "drwx------ 2 root root        4096 Jul 19 14:11  exported_data\n",
            "-rw------- 1 root root     6312355 Jul 25 04:24  teacher_best.pt\n",
            "lrw------- 1 root root           0 Jul 25 04:25  uavid_yolo_labels -> /content/drive/.shortcut-targets-by-id/1rl-WOOOuvuvXmciZUPLst2InKEsQItXg/uavid_yolo_labels\n",
            "-rw------- 1 root root 11754498403 Jul 25 04:24  uavid.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/MyDrive/uavid.zip\" \"/content/\""
      ],
      "metadata": {
        "id": "jeKgG7b10WYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r \"/content/drive/MyDrive/uavid_yolo_labels\" \"/content/\""
      ],
      "metadata": {
        "id": "L46Y8gwJ4UvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q uavid.zip"
      ],
      "metadata": {
        "id": "V5uqtsLe1i7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/visdrone-dataset.zip"
      ],
      "metadata": {
        "id": "pcENkRFU1qG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj8M20Qd1tq2",
        "outputId": "62ea23e2-9ddd-42eb-cf5e-c8c411631482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.169-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.16.0)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.7.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.7.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.169-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m120.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.169 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Config\n",
        "image_dir = \"/content/uavid_train/seq1/Images\"      # Original image directory\n",
        "label_dir = \"/content/uavid_yolo_labels/seq1/labels\"      # Original label directory\n",
        "dataset_path = \"my_dataset\"            # Output directory\n",
        "val_ratio = 0.2                        # 80% train, 20% validation\n",
        "\n",
        "# Create folders\n",
        "os.makedirs(f\"{dataset_path}/images/train\", exist_ok=True)\n",
        "os.makedirs(f\"{dataset_path}/images/val\", exist_ok=True)\n",
        "os.makedirs(f\"{dataset_path}/labels/train\", exist_ok=True)\n",
        "os.makedirs(f\"{dataset_path}/labels/val\", exist_ok=True)\n",
        "\n",
        "# Get image filenames (without extensions)\n",
        "image_files = [f.split('.')[0] for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "image_files_train, image_files_val = train_test_split(image_files, test_size=val_ratio, random_state=42)\n",
        "\n",
        "# Helper function to copy files\n",
        "def copy_files(filenames, source_dir, dest_dir_img, dest_dir_label, ext=\".png\"):\n",
        "    for f in filenames:\n",
        "        # Copy image\n",
        "        shutil.copy2(\n",
        "            os.path.join(source_dir, f + ext),\n",
        "            os.path.join(dest_dir_img, f + ext)\n",
        "        )\n",
        "        # Copy label\n",
        "        label_file = f + \".txt\"\n",
        "        shutil.copy2(\n",
        "            os.path.join(label_dir, label_file),\n",
        "            os.path.join(dest_dir_label, label_file)\n",
        "        )\n",
        "\n",
        "# Copy train/val data\n",
        "copy_files(image_files_train, image_dir, f\"{dataset_path}/images/train\", f\"{dataset_path}/labels/train\")\n",
        "copy_files(image_files_val, image_dir, f\"{dataset_path}/images/val\", f\"{dataset_path}/labels/val\")\n",
        "\n",
        "print(f\"Train: {len(image_files_train)} images | Val: {len(image_files_val)} images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX8xeBbs1ws1",
        "outputId": "45f2e323-ad9a-4565-b5d0-989336b5acaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 480 images | Val: 120 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "\n",
        "# 1. Paths\n",
        "LABELED_DATA_YAML = os.path.join('/content/my_dataset', 'student_data.yaml')\n",
        "with open(LABELED_DATA_YAML, 'w') as f:\n",
        "    f.write(f\"path: {os.path.abspath('/content/my_dataset')}\\n\")\n",
        "    f.write(\"train: images/train\\n\")\n",
        "    # You should copy your original validation set for a proper evaluation\n",
        "    f.write(\"val: images/val\\n\\n\")\n",
        "    f.write(\"nc: 3\\n\")\n",
        "    f.write(\"names:\")\n",
        "    # Add your class names here, matching the original data.yaml\n",
        "    f.write(\" ['building' , 'tree' , 'low vegetation']\")\n",
        "UNLABELED_IMAGES_DIR = '/content/VisDrone2019-DET-train/VisDrone2019-DET-train/images'\n",
        "COMBINED_DATASET_DIR = 'combined_dataset/'\n",
        "\n",
        "# 2. Teacher Model Training Parameters\n",
        "TEACHER_MODEL_PATH = 'yolov8n.pt'  # Start with pre-trained weights\n",
        "TEACHER_EPOCHS = 50\n",
        "TEACHER_IMG_SIZE = 1280\n",
        "TEACHER_BATCH_SIZE = 8\n",
        "TEACHER_PROJECT_NAME = 'teacher_training'\n",
        "\n",
        "# 3. Pseudo-Labeling Parameters\n",
        "CONFIDENCE_THRESHOLD = 0.85  # Only save predictions with confidence > 85%\n",
        "\n",
        "# 4. Student Model Training Parameters\n",
        "STUDENT_MODEL_PATH = 'yolov8n.pt' # Start student from the same pre-trained weights\n",
        "STUDENT_EPOCHS = 100 # Train for more epochs on the larger dataset\n",
        "STUDENT_IMG_SIZE = 1280\n",
        "STUDENT_BATCH_SIZE = 8\n",
        "STUDENT_PROJECT_NAME = 'student_training'\n",
        "\n",
        "# --- STEP 2: GENERATE AND FILTER PSEUDO-LABELS ---\n",
        "print(f\"--- Generating Pseudo-Labels with Confidence Threshold > {CONFIDENCE_THRESHOLD} ---\")\n",
        "\n",
        "best_teacher_weights = '/content/drive/MyDrive/teacher_best.pt'\n",
        "# Load the trained teacher model\n",
        "teacher_model = YOLO(best_teacher_weights)\n",
        "\n",
        "# Create a directory to store the pseudo-labels\n",
        "pseudo_labels_dir = os.path.join(COMBINED_DATASET_DIR, 'train/labels/')\n",
        "os.makedirs(pseudo_labels_dir, exist_ok=True)\n",
        "\n",
        "# Get list of unlabeled images\n",
        "unlabeled_images = os.listdir(UNLABELED_IMAGES_DIR)\n",
        "\n",
        "for image_name in unlabeled_images:\n",
        "    image_path = os.path.join(UNLABELED_IMAGES_DIR, image_name)\n",
        "\n",
        "    # Run inference\n",
        "    results = teacher_model.predict(image_path, verbose=False)\n",
        "\n",
        "    # Get the base name of the image file (without extension)\n",
        "    base_name = os.path.splitext(image_name)\n",
        "    label_path = os.path.join(pseudo_labels_dir, f'{base_name}.txt')\n",
        "\n",
        "    # Save high-confidence predictions to a YOLO format.txt file\n",
        "    with open(label_path, 'w') as f:\n",
        "      if results[0].boxes is not None:\n",
        "        for box in results[0].boxes:\n",
        "            class_id = int(box.cls.item())  # Added .item() to get scalar value\n",
        "\n",
        "            # Extract coordinates properly\n",
        "            coords = box.xywhn[0]  # Get first (and only) element of batch\n",
        "            x_center = coords[0].item()\n",
        "            y_center = coords[1].item()\n",
        "            width = coords[2].item()\n",
        "            height = coords[3].item()\n",
        "            f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
        "\n",
        "print(f\"--- Pseudo-Label Generation Complete. Labels saved in {pseudo_labels_dir} ---\")\n",
        "\n",
        "\n",
        "# --- STEP 3: COMBINE THE DATASETS ---\n",
        "print(\"--- Combining Labeled and Pseudo-Labeled Datasets ---\")\n",
        "\n",
        "# Create directory structure for the combined dataset\n",
        "combined_images_dir = os.path.join(COMBINED_DATASET_DIR, 'train/images/')\n",
        "os.makedirs(combined_images_dir, exist_ok=True)\n",
        "\n",
        "# a) Copy original labeled images and labels\n",
        "# Assuming the original labeled dataset is in 'labeled_dataset/train/'\n",
        "original_images_dir = '/content/my_dataset/images/train'\n",
        "original_labels_dir = '/content/my_dataset/labels/train'\n",
        "\n",
        "for filename in os.listdir(original_images_dir):\n",
        "    shutil.copy(os.path.join(original_images_dir, filename), combined_images_dir)\n",
        "for filename in os.listdir(original_labels_dir):\n",
        "    shutil.copy(os.path.join(original_labels_dir, filename), pseudo_labels_dir)\n",
        "\n",
        "# b) Copy unlabeled images (which now have pseudo-labels)\n",
        "for filename in os.listdir(UNLABELED_IMAGES_DIR):\n",
        "    shutil.copy(os.path.join(UNLABELED_IMAGES_DIR, filename), combined_images_dir)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1R4NpH212NW",
        "outputId": "3e58473e-0265-4d2f-c048-7f6b36b9389c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Generating Pseudo-Labels with Confidence Threshold > 0.85 ---\n",
            "--- Pseudo-Label Generation Complete. Labels saved in combined_dataset/train/labels/ ---\n",
            "--- Combining Labeled and Pseudo-Labeled Datasets ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset paths\n",
        "image_dir = '/content/combined_dataset/train/images'\n",
        "label_dir = '/content/combined_dataset/train/labels'\n",
        "\n",
        "# Class mapping (model class ID -> target class ID in your dataset)\n",
        "class_mapping = {\n",
        "    0: 3,\n",
        "    1: 4# Model's class 0 becomes class 5 in your labels\n",
        "}\n",
        "\n",
        "conf_threshold = 0.1  # Minimum confidence score"
      ],
      "metadata": {
        "id": "lAX3m2gC6ecG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers timm torch opencv-python supervision\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection\n",
        "import supervision as sv\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Use the standard OWL-ViT model from Google\n",
        "model_name = \"google/owlvit-base-patch32\"\n",
        "processor = AutoProcessor.from_pretrained(model_name)\n",
        "model = AutoModelForZeroShotObjectDetection.from_pretrained(model_name)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8055a0d980ae47ab86f391bf26303b8f",
            "9e68753a90bf47ae8ff7ab97f5c276f4",
            "5fbe77f96f3c40109d4e38552914729a",
            "ab1b43512d4643e09a9e6f2e2c5fbac7",
            "80bf0a56c82941c0a6b34b8c25331624",
            "d3da98336dfb4a7bb05390307309948e",
            "3fb3561d71f94ec48645c33ca5da88f9",
            "f438b64691644808b3e2ae1f99f0a5e6",
            "a5ff6b22085a468ea78315ee0e5f8587",
            "deb02bd89593489089763ae1b512549b",
            "6933af07440448bba15e94dcb737c576",
            "48d102aaf79e4653929dacd028cb962a",
            "ada49bed29614c92ac4023d6d67fcf82",
            "76aa2b0011314dd2ba5dcbf5bba0eae6",
            "66d303cbbbd947ef99459e6ca493ef8d",
            "b8bacbf959a8425baa9e4594d94e397d",
            "fd5505e4c7cb4f1cb24a3c930b7b1e72",
            "62f9a56e03304292a05e040df3e1d4f9",
            "9d1f509b295f481384344d52d210ca34",
            "382eef49c05b4aa38cc307b873d879ed",
            "73d41e6bc08e4e1c9914564f7ef5364c",
            "6022ec4bff4d4e68a1bda06f82e07d5d",
            "60ace339c9d54d9cb43ca61cfc54c20f",
            "12e101ebbd1542f89efe090cebaff2e7",
            "17e85fb9e6f345bcb6ab7d4e974e8e35",
            "d45950ca2a234f52a35028192f8ecc91",
            "2e72a175821740f4b6db8faee096c525",
            "e38976271ffb41c5ab7af212853f93b1",
            "b0543129faf045d48d65d594756a6548",
            "46c2b23981174a199dff317e3a9effdc",
            "8367f42debb342c2946d93ae653ec0e2",
            "ceeef6bb6dab431687d6ad301bc7867c",
            "79d3d2bdbcb04deba85f248d99444d01",
            "3d70b8e5fccc4697a9ff17ee3927b229",
            "40ed1ede7a8143f199c21faf2a7ade00",
            "089bbda4437b4cddb38117c76943d60e",
            "0eb3c5ebda07401e92888a353c4cc5fb",
            "04d5dcae45d040de8fe046d8076ef538",
            "4270f98550eb4a629c0a1ee62469a6b2",
            "32d302649fb14a089205048f0c1aeb96",
            "60d581706711479b8285c157b4b8879e",
            "99999e4a4e844e8aa83c65ca3499dc71",
            "7a867acbddb94896a300c9dfeb240bc1",
            "c4672705cb9040d1bea599b2b33f3713",
            "9d871104dcdd4589a8615ec28cf60eb1",
            "14873424fe504aedb1b02b3757df488e",
            "14d9bdb13b514425bcc4104ca0fc810a",
            "7f3269510a0c4bd582834d024f4ebdf5",
            "027c279284bf4b16a7cec24f1ed5fdf5",
            "1bcdf734e8744fedbb9b0b0f6ed96136",
            "a862a5e6c3b34b25a60d54f125ce5e46",
            "874a5321b6d342c4bdb97045f7955ce5",
            "3c735a999d6043ebbda690f134298969",
            "ac77af979975410eb7115e6f12ea9fa3",
            "4ac28623c2be47eb8e75587cf242d48c",
            "6e86b3272d6e498eb1803214e0f570ae",
            "62b12b4709cc4456aaafb373b208dacf",
            "6f34e51ea56d49ce99a49ceda4dff6e2",
            "0b363648bbac40b38953046a16df6381",
            "0dffb467485f43a3b2580cd6729e3ab1",
            "e0bd59bedc33400fb83815aa5b8703dc",
            "47647611ad454afba42ef69f9e5242df",
            "4c239b425a91455fa4b3ddd447f78006",
            "b3514d8758734c5b971d461f4d15b5d7",
            "b4e653abfaac4cc7bd581e1094950542",
            "cdd6f1b3784e43ddadd58c7edeef9f4e",
            "3105091331cb47ebbb7b35e08fd12ea5",
            "bdc99ba55d184b41a5646aa20e0822c9",
            "8c3ccc638b7f490b810a7eb1b71f8ebe",
            "2900b8a303f04367a613379efebc0228",
            "c4b6349914a6426682bf82c22bf6cb68",
            "4a785004bd744aa0bfbd9b76950a1db8",
            "bf75b9b053a7430ca26c158d47ff68c9",
            "7e5fe5d2d1f24c04be079d753c4133bd",
            "258d4c7da8eb43aaab81ec85a8219af2",
            "4e97440fa9154651ac3ed6f64c28c1c0",
            "da48328f2b4f44ada9c02f67ee953968"
          ]
        },
        "id": "enQgCvxr72fx",
        "outputId": "76338072-8bbd-4ac7-d13a-23c04ad4eb4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/207.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.2/207.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/392 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8055a0d980ae47ab86f391bf26303b8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/775 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48d102aaf79e4653929dacd028cb962a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60ace339c9d54d9cb43ca61cfc54c20f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d70b8e5fccc4697a9ff17ee3927b229"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d871104dcdd4589a8615ec28cf60eb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e86b3272d6e498eb1803214e0f570ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/613M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3105091331cb47ebbb7b35e08fd12ea5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OwlViTForObjectDetection(\n",
              "  (owlvit): OwlViTModel(\n",
              "    (text_model): OwlViTTextTransformer(\n",
              "      (embeddings): OwlViTTextEmbeddings(\n",
              "        (token_embedding): Embedding(49408, 512)\n",
              "        (position_embedding): Embedding(16, 512)\n",
              "      )\n",
              "      (encoder): OwlViTEncoder(\n",
              "        (layers): ModuleList(\n",
              "          (0-11): 12 x OwlViTEncoderLayer(\n",
              "            (self_attn): OwlViTAttention(\n",
              "              (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "              (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            )\n",
              "            (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): OwlViTMLP(\n",
              "              (activation_fn): QuickGELUActivation()\n",
              "              (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "              (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            )\n",
              "            (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (vision_model): OwlViTVisionTransformer(\n",
              "      (embeddings): OwlViTVisionEmbeddings(\n",
              "        (patch_embedding): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
              "        (position_embedding): Embedding(577, 768)\n",
              "      )\n",
              "      (pre_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (encoder): OwlViTEncoder(\n",
              "        (layers): ModuleList(\n",
              "          (0-11): 12 x OwlViTEncoderLayer(\n",
              "            (self_attn): OwlViTAttention(\n",
              "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (mlp): OwlViTMLP(\n",
              "              (activation_fn): QuickGELUActivation()\n",
              "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            )\n",
              "            (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (visual_projection): Linear(in_features=768, out_features=512, bias=False)\n",
              "    (text_projection): Linear(in_features=512, out_features=512, bias=False)\n",
              "  )\n",
              "  (class_head): OwlViTClassPredictionHead(\n",
              "    (dense0): Linear(in_features=768, out_features=512, bias=True)\n",
              "    (logit_shift): Linear(in_features=768, out_features=1, bias=True)\n",
              "    (logit_scale): Linear(in_features=768, out_features=1, bias=True)\n",
              "    (elu): ELU(alpha=1.0)\n",
              "  )\n",
              "  (box_head): OwlViTBoxPredictionHead(\n",
              "    (dense0): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dense1): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (gelu): GELU(approximate='none')\n",
              "    (dense2): Linear(in_features=768, out_features=4, bias=True)\n",
              "  )\n",
              "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_queries = [\"transmission tower\", \"communication tower\"]\n",
        "# Get all image paths (both JPG and PNG)\n",
        "image_paths = []\n",
        "for ext in ('*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG'):\n",
        "    image_paths.extend(glob.glob(os.path.join(image_dir, ext)))\n",
        "\n",
        "for img_path in image_paths:\n",
        "    # Get corresponding label path\n",
        "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "    label_path = os.path.join(label_dir, f\"{base_name}.txt\")\n",
        "\n",
        "    # Read existing labels (if any)\n",
        "    existing_boxes = []\n",
        "    if os.path.exists(label_path):\n",
        "        with open(label_path, 'r') as f:\n",
        "            existing_boxes = f.readlines()\n",
        "\n",
        "    # Load image with PIL (required by OWL-ViT)\n",
        "    image = Image.open(img_path).convert(\"RGB\")\n",
        "    width, height = image.size\n",
        "\n",
        "    # Prepare inputs for OWL-ViT\n",
        "    inputs = processor(\n",
        "        text=text_queries,\n",
        "        images=image,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "\n",
        "    # Run inference\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Process predictions\n",
        "    target_sizes = torch.tensor([image.size[::-1]])\n",
        "    results = processor.post_process_grounded_object_detection(\n",
        "        outputs=outputs,\n",
        "        threshold=conf_threshold,\n",
        "        target_sizes=target_sizes\n",
        "    )[0]\n",
        "\n",
        "    # Extract detections\n",
        "    new_boxes = []\n",
        "    for box, score, label in zip(results[\"boxes\"], results[\"scores\"], results[\"labels\"]):\n",
        "        # Skip if label not in mapping\n",
        "        if label.item() not in class_mapping:\n",
        "            continue\n",
        "\n",
        "        # Convert to normalized YOLO format\n",
        "        x_min, y_min, x_max, y_max = box.tolist()\n",
        "\n",
        "        # Normalize coordinates\n",
        "        x_center = (x_min + x_max) / 2 / width\n",
        "        y_center = (y_min + y_max) / 2 / height\n",
        "        w = (x_max - x_min) / width\n",
        "        h = (y_max - y_min) / height\n",
        "\n",
        "        # Format: class_id x_center y_center width height\n",
        "        new_boxes.append(\n",
        "            f\"{class_mapping[label.item()]} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\\n\"\n",
        "        )\n",
        "\n",
        "    # Write back original labels + new detections\n",
        "    with open(label_path, 'w') as f:\n",
        "        # Write existing boxes first\n",
        "        f.writelines(existing_boxes)\n",
        "        # Append new boxes\n",
        "        f.writelines(new_boxes)"
      ],
      "metadata": {
        "id": "xeX2DRHl7vJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/combined_dataset /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "fod5CKJODi75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##"
      ],
      "metadata": {
        "id": "JVprbP-UI5SN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5DX95rWvWSN",
        "outputId": "1e9370cc-3697-41e8-c3d0-97aaabe71c59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/combined_dataset /content"
      ],
      "metadata": {
        "id": "60Gh4YXfvzDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/combined_dataset /content/data1"
      ],
      "metadata": {
        "id": "2IszexjVw9i0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/combined_dataset /content/data2"
      ],
      "metadata": {
        "id": "JhVBJevfxJSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Tx2ExPQrUJN",
        "outputId": "cc3346ee-1306-4e59-d1cb-9876095b3c11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Solution 1: 100%|██████████| 6951/6951 [10:18<00:00, 11.24it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solution 1: Removed 780 images with only low vegetation or empty labels\n",
            "Dataset reduction complete!\n",
            "Removed files are backed up at: /content/backup\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set your paths here\n",
        "IMAGES_DIR = \"/content/data1/train/images\"  # Path to your images folder\n",
        "LABELS_DIR = \"/content/data1/train/labels\"  # Path to your labels folder\n",
        "BACKUP_DIR = \"/content/backup\"  # Backup directory for removed files\n",
        "\n",
        "# Create backup directories\n",
        "os.makedirs(os.path.join(BACKUP_DIR, \"images\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(BACKUP_DIR, \"labels\"), exist_ok=True)\n",
        "\n",
        "# ========================\n",
        "# SOLUTION 1: Remove empty or only low-vegetation annotations\n",
        "# ========================\n",
        "def remove_empty_or_low_veg(images_dir, labels_dir, backup_dir):\n",
        "    \"\"\"Remove images/labels that are empty or contain only low vegetation (class 2)\"\"\"\n",
        "    removed_count = 0\n",
        "    for label_file in tqdm(os.listdir(labels_dir), desc=\"Processing Solution 1\"):\n",
        "        label_path = os.path.join(labels_dir, label_file)\n",
        "        image_file = os.path.splitext(label_file)[0]  # Remove .txt extension\n",
        "\n",
        "        # Find matching image with any extension\n",
        "        image_path = None\n",
        "        for ext in ['.jpg', '.jpeg', '.png', '.bmp']:\n",
        "            possible_path = os.path.join(images_dir, image_file + ext)\n",
        "            if os.path.exists(possible_path):\n",
        "                image_path = possible_path\n",
        "                break\n",
        "\n",
        "        if not image_path:\n",
        "            continue\n",
        "\n",
        "        # Check label content\n",
        "        with open(label_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        # Get unique classes in the file\n",
        "        classes = set()\n",
        "        for line in lines:\n",
        "            if line.strip():  # Skip empty lines\n",
        "                try:\n",
        "                    cls_id = int(line.split()[0])\n",
        "                    classes.add(cls_id)\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        # Remove if: empty or contains only class 2 (low vegetation)\n",
        "        if not classes or classes == {2}:\n",
        "            # Move files to backup\n",
        "            shutil.move(image_path, os.path.join(backup_dir, \"images\", os.path.basename(image_path)))\n",
        "            shutil.move(label_path, os.path.join(backup_dir, \"labels\", label_file))\n",
        "            removed_count += 1\n",
        "\n",
        "    print(f\"Solution 1: Removed {removed_count} images with only low vegetation or empty labels\")\n",
        "\n",
        "# ========================\n",
        "# SOLUTION 2: Remove images with <3 annotations\n",
        "# ========================\n",
        "def remove_few_annotations(images_dir, labels_dir, backup_dir, min_annotations=3):\n",
        "    \"\"\"Remove images with fewer than min_annotations\"\"\"\n",
        "    removed_count = 0\n",
        "    for label_file in tqdm(os.listdir(labels_dir), desc=\"Processing Solution 2\"):\n",
        "        label_path = os.path.join(labels_dir, label_file)\n",
        "        image_file = os.path.splitext(label_file)[0]  # Remove .txt extension\n",
        "\n",
        "        # Find matching image with any extension\n",
        "        image_path = None\n",
        "        for ext in ['.jpg', '.jpeg', '.png', '.bmp']:\n",
        "            possible_path = os.path.join(images_dir, image_file + ext)\n",
        "            if os.path.exists(possible_path):\n",
        "                image_path = possible_path\n",
        "                break\n",
        "\n",
        "        if not image_path:\n",
        "            continue\n",
        "\n",
        "        # Count valid annotations\n",
        "        with open(label_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        valid_annotations = 0\n",
        "        for line in lines:\n",
        "            if line.strip():  # Count non-empty lines\n",
        "                valid_annotations += 1\n",
        "\n",
        "        # Remove if doesn't meet minimum annotations\n",
        "        if valid_annotations < min_annotations:\n",
        "            # Move files to backup\n",
        "            shutil.move(image_path, os.path.join(backup_dir, \"images\", os.path.basename(image_path)))\n",
        "            shutil.move(label_path, os.path.join(backup_dir, \"labels\", label_file))\n",
        "            removed_count += 1\n",
        "\n",
        "    print(f\"Solution 2: Removed {removed_count} images with fewer than {min_annotations} annotations\")\n",
        "\n",
        "# ========================\n",
        "# EXECUTION\n",
        "# ========================\n",
        "# Run Solution 1\n",
        "remove_empty_or_low_veg(IMAGES_DIR, LABELS_DIR, BACKUP_DIR)\n",
        "\n",
        "# Run Solution 2\n",
        "#remove_few_annotations(IMAGES_DIR, LABELS_DIR, BACKUP_DIR, min_annotations=3)\n",
        "\n",
        "print(\"Dataset reduction complete!\")\n",
        "print(f\"Removed files are backed up at: {BACKUP_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set your paths here\n",
        "IMAGES_DIR = \"/content/data2/train/images\"  # Path to your images folder\n",
        "LABELS_DIR = \"/content/data2/train/labels\"  # Path to your labels folder\n",
        "BACKUP_DIR = \"/content/backup2\"  # Backup directory for removed files\n",
        "\n",
        "# Create backup directories\n",
        "os.makedirs(os.path.join(BACKUP_DIR, \"images\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(BACKUP_DIR, \"labels\"), exist_ok=True)\n",
        "\n",
        "# ========================\n",
        "# SOLUTION 1: Remove empty or only low-vegetation annotations\n",
        "# ========================\n",
        "def remove_empty_or_low_veg(images_dir, labels_dir, backup_dir):\n",
        "    \"\"\"Remove images/labels that are empty or contain only low vegetation (class 2)\"\"\"\n",
        "    removed_count = 0\n",
        "    for label_file in tqdm(os.listdir(labels_dir), desc=\"Processing Solution 1\"):\n",
        "        label_path = os.path.join(labels_dir, label_file)\n",
        "        image_file = os.path.splitext(label_file)[0]  # Remove .txt extension\n",
        "\n",
        "        # Find matching image with any extension\n",
        "        image_path = None\n",
        "        for ext in ['.jpg', '.jpeg', '.png', '.bmp']:\n",
        "            possible_path = os.path.join(images_dir, image_file + ext)\n",
        "            if os.path.exists(possible_path):\n",
        "                image_path = possible_path\n",
        "                break\n",
        "\n",
        "        if not image_path:\n",
        "            continue\n",
        "\n",
        "        # Check label content\n",
        "        with open(label_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        # Get unique classes in the file\n",
        "        classes = set()\n",
        "        for line in lines:\n",
        "            if line.strip():  # Skip empty lines\n",
        "                try:\n",
        "                    cls_id = int(line.split()[0])\n",
        "                    classes.add(cls_id)\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        # Remove if: empty or contains only class 2 (low vegetation)\n",
        "        if not classes or classes == {2}:\n",
        "            # Move files to backup\n",
        "            shutil.move(image_path, os.path.join(backup_dir, \"images\", os.path.basename(image_path)))\n",
        "            shutil.move(label_path, os.path.join(backup_dir, \"labels\", label_file))\n",
        "            removed_count += 1\n",
        "\n",
        "    print(f\"Solution 1: Removed {removed_count} images with only low vegetation or empty labels\")\n",
        "\n",
        "# ========================\n",
        "# SOLUTION 2: Remove images with <3 annotations\n",
        "# ========================\n",
        "def remove_few_annotations(images_dir, labels_dir, backup_dir, min_annotations=3):\n",
        "    \"\"\"Remove images with fewer than min_annotations\"\"\"\n",
        "    removed_count = 0\n",
        "    for label_file in tqdm(os.listdir(labels_dir), desc=\"Processing Solution 2\"):\n",
        "        label_path = os.path.join(labels_dir, label_file)\n",
        "        image_file = os.path.splitext(label_file)[0]  # Remove .txt extension\n",
        "\n",
        "        # Find matching image with any extension\n",
        "        image_path = None\n",
        "        for ext in ['.jpg', '.jpeg', '.png', '.bmp']:\n",
        "            possible_path = os.path.join(images_dir, image_file + ext)\n",
        "            if os.path.exists(possible_path):\n",
        "                image_path = possible_path\n",
        "                break\n",
        "\n",
        "        if not image_path:\n",
        "            continue\n",
        "\n",
        "        # Count valid annotations\n",
        "        with open(label_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        valid_annotations = 0\n",
        "        for line in lines:\n",
        "            if line.strip():  # Count non-empty lines\n",
        "                valid_annotations += 1\n",
        "\n",
        "        # Remove if doesn't meet minimum annotations\n",
        "        if valid_annotations < min_annotations:\n",
        "            # Move files to backup\n",
        "            shutil.move(image_path, os.path.join(backup_dir, \"images\", os.path.basename(image_path)))\n",
        "            shutil.move(label_path, os.path.join(backup_dir, \"labels\", label_file))\n",
        "            removed_count += 1\n",
        "\n",
        "    print(f\"Solution 2: Removed {removed_count} images with fewer than {min_annotations} annotations\")\n",
        "\n",
        "# ========================\n",
        "# EXECUTION\n",
        "# ========================\n",
        "# Run Solution 1\n",
        "#remove_empty_or_low_veg(IMAGES_DIR, LABELS_DIR, BACKUP_DIR)\n",
        "\n",
        "# Run Solution 2\n",
        "remove_few_annotations(IMAGES_DIR, LABELS_DIR, BACKUP_DIR, min_annotations=3)\n",
        "\n",
        "print(\"Dataset reduction complete!\")\n",
        "print(f\"Removed files are backed up at: {BACKUP_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmvNMXYUxVRi",
        "outputId": "1d9e2b38-5da4-415e-c753-0b1fbfaf82b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Solution 2: 100%|██████████| 6171/6171 [11:51<00:00,  8.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solution 2: Removed 1523 images with fewer than 3 annotations\n",
            "Dataset reduction complete!\n",
            "Removed files are backed up at: /content/backup\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/data2 /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "nyi5Yag15yOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##"
      ],
      "metadata": {
        "id": "5OcAjhYUJJiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JUuajuJwY0M",
        "outputId": "eaf7c08f-24c2-4dbf-98d9-2a9ef8347391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "import yaml\n",
        "\n",
        "def yolo_train_val_split(dataset_path, output_path, train_ratio=0.8, seed=42):\n",
        "    \"\"\"\n",
        "    Split YOLO formatted dataset into train/validation sets\n",
        "\n",
        "    Args:\n",
        "        dataset_path: Path to dataset (should contain 'images' and 'labels' folders)\n",
        "        output_path: Where to save the split datasets\n",
        "        train_ratio: Percentage of data for training (0-1)\n",
        "        seed: Random seed for reproducibility\n",
        "    \"\"\"\n",
        "    # Create directories\n",
        "    os.makedirs(os.path.join(output_path, 'train/images'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_path, 'train/labels'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_path, 'val/images'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_path, 'val/labels'), exist_ok=True)\n",
        "\n",
        "    # Get list of image files (supporting both .jpg and .png)\n",
        "    images_dir = os.path.join(dataset_path, 'images')\n",
        "    labels_dir = os.path.join(dataset_path, 'labels')\n",
        "\n",
        "    # Supported image extensions\n",
        "    image_extensions = ('.jpg', '.jpeg', '.png')\n",
        "    image_files = [f for f in os.listdir(images_dir)\n",
        "                  if f.lower().endswith(image_extensions)]\n",
        "\n",
        "    # Split into train and val sets\n",
        "    train_files, val_files = train_test_split(\n",
        "        image_files,\n",
        "        train_size=train_ratio,\n",
        "        random_state=seed\n",
        "    )\n",
        "\n",
        "    # Helper function to copy files\n",
        "    def copy_files(files, split_type):\n",
        "        for file in files:\n",
        "            # Copy image\n",
        "            shutil.copy(\n",
        "                os.path.join(images_dir, file),\n",
        "                os.path.join(output_path, split_type, 'images', file)\n",
        "            )\n",
        "\n",
        "            # Copy corresponding label file\n",
        "            base_name = os.path.splitext(file)[0]  # Get filename without extension\n",
        "            possible_label_files = [\n",
        "                f\"{base_name}.txt\",                  # Standard YOLO format\n",
        "                f\"{base_name}.TXT\",                  # Some systems may capitalize\n",
        "                f\"{base_name}.text\"                 # Rare but possible\n",
        "            ]\n",
        "\n",
        "            for label_file in possible_label_files:\n",
        "                src_label = os.path.join(labels_dir, label_file)\n",
        "                if os.path.exists(src_label):\n",
        "                    shutil.copy(\n",
        "                        src_label,\n",
        "                        os.path.join(output_path, split_type, 'labels', f\"{base_name}.txt\")\n",
        "                    )\n",
        "                    break\n",
        "            else:\n",
        "                print(f\"Warning: No label file found for {file}\")\n",
        "\n",
        "    # Perform the copying\n",
        "    copy_files(train_files, 'train')\n",
        "    copy_files(val_files, 'val')\n",
        "\n",
        "    print(f\"\\nSplit completed:\\n\"\n",
        "          f\"Total images: {len(image_files)}\\n\"\n",
        "          f\"Training samples: {len(train_files)} ({len(train_files)/len(image_files):.1%})\\n\"\n",
        "          f\"Validation samples: {len(val_files)} ({len(val_files)/len(image_files):.1%})\\n\")\n",
        "\n",
        "    # Create data.yaml file\n",
        "    class_names = ['building', 'tree', 'low vegetation', 'transmission tower', 'communication tower']\n",
        "    yaml_content = {\n",
        "        'path': output_path,\n",
        "        'train': 'train/images',\n",
        "        'val': 'val/images',\n",
        "        'names': {i: name for i, name in enumerate(class_names)},\n",
        "        'nc': len(class_names)\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(output_path, 'data.yaml'), 'w') as f:\n",
        "        yaml.dump(yaml_content, f, sort_keys=False)\n",
        "\n",
        "    print(f\"Created data.yaml configuration file at: {os.path.join(output_path, 'data.yaml')}\")\n",
        "    print(\"\\nFinal directory structure:\")\n",
        "    print(f\"{output_path}\")\n",
        "    print(\"├── train/\")\n",
        "    print(\"│   ├── images/\")\n",
        "    print(\"│   └── labels/\")\n",
        "    print(\"├── val/\")\n",
        "    print(\"│   ├── images/\")\n",
        "    print(\"│   └── labels/\")\n",
        "    print(\"└── data.yaml\")\n",
        "\n",
        "# Example usage (for Google Colab):\n",
        "if __name__ == \"__main__\":\n",
        "    # Mount Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Set your paths (modify these)\n",
        "    raw_dataset_path = \"/content/drive/MyDrive/data2/train\"  # Contains images/ and labels/\n",
        "    output_path = \"/content/drive/MyDrive/split\"    # Where to save split dataset\n",
        "\n",
        "    # Perform the split (80% train, 20% val)\n",
        "    yolo_train_val_split(\n",
        "        dataset_path=raw_dataset_path,\n",
        "        output_path=output_path,\n",
        "        train_ratio=0.8,\n",
        "        seed=42\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZUq-McHwZkd",
        "outputId": "75cbaade-24a9-4db9-8683-adc1bbfe77b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Split completed:\n",
            "Total images: 4648\n",
            "Training samples: 3718 (80.0%)\n",
            "Validation samples: 930 (20.0%)\n",
            "\n",
            "Created data.yaml configuration file at: /content/drive/MyDrive/split/data.yaml\n",
            "\n",
            "Final directory structure:\n",
            "/content/drive/MyDrive/split\n",
            "├── train/\n",
            "│   ├── images/\n",
            "│   └── labels/\n",
            "├── val/\n",
            "│   ├── images/\n",
            "│   └── labels/\n",
            "└── data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive (if needed)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set your image and label directories\n",
        "images_dir = Path('/content/drive/MyDrive/split/val/images')  # 👈 UPDATE TO YOUR IMAGES PATH\n",
        "labels_dir = Path('/content/drive/MyDrive/split/val/labels')  # 👈 UPDATE TO YOUR LABELS PATH\n",
        "\n",
        "# Supported image extensions\n",
        "image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']\n",
        "\n",
        "# Create lists of files\n",
        "image_files = [f for f in images_dir.iterdir() if f.suffix.lower() in image_extensions]\n",
        "label_files = [f for f in labels_dir.iterdir() if f.suffix.lower() == '.txt']\n",
        "\n",
        "# Convert to sets for faster lookup\n",
        "image_stems = {f.stem for f in image_files}\n",
        "label_stems = {f.stem for f in label_files}\n",
        "\n",
        "# Find missing labels\n",
        "images_without_labels = []\n",
        "for img_stem in image_stems:\n",
        "    if img_stem not in label_stems:\n",
        "        # Find the full filename of the image without label\n",
        "        for img_file in image_files:\n",
        "            if img_file.stem == img_stem:\n",
        "                images_without_labels.append(img_file.name)\n",
        "                break\n",
        "\n",
        "# Find orphan labels (optional)\n",
        "orphan_labels = [f.name for f in label_files if f.stem not in image_stems]\n",
        "\n",
        "# Display results\n",
        "print(f\"Total images: {len(image_files)}\")\n",
        "print(f\"Total labels: {len(label_files)}\")\n",
        "print(f\"\\nImages without labels: {len(images_without_labels)}\")\n",
        "print(\"-----------------------------------\")\n",
        "\n",
        "if images_without_labels:\n",
        "    print(\"Missing label files for these images:\")\n",
        "    for img in images_without_labels[:20]:  # Show first 20 to avoid flooding output\n",
        "        print(f\" - {img}\")\n",
        "    if len(images_without_labels) > 20:\n",
        "        print(f\"... and {len(images_without_labels) - 20} more\")\n",
        "else:\n",
        "    print(\"✅ All images have corresponding labels!\")\n",
        "\n",
        "print(f\"\\nOrphan labels (without images): {len(orphan_labels)}\")\n",
        "if orphan_labels:\n",
        "    print(\"Consider deleting these label files:\")\n",
        "    for lbl in orphan_labels[:20]:  # Show first 20\n",
        "        print(f\" - {lbl}\")\n",
        "    if len(orphan_labels) > 20:\n",
        "        print(f\"... and {len(orphan_labels) - 20} more\")\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\n--- Validation Summary ---\")\n",
        "print(f\"Images with labels: {len(image_files) - len(images_without_labels)}\")\n",
        "print(f\"Images without labels: {len(images_without_labels)}\")\n",
        "print(f\"Orphan label files: {len(orphan_labels)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HDiorbO-vMs",
        "outputId": "d8966283-087a-495d-a1eb-c838535ba4b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Total images: 930\n",
            "Total labels: 930\n",
            "\n",
            "Images without labels: 0\n",
            "-----------------------------------\n",
            "✅ All images have corresponding labels!\n",
            "\n",
            "Orphan labels (without images): 0\n",
            "\n",
            "--- Validation Summary ---\n",
            "Images with labels: 930\n",
            "Images without labels: 0\n",
            "Orphan label files: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nopy1uM1uBFy",
        "outputId": "a1e04195-eed4-4d82-deb3-be4ed893b61b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset configuration:\n",
            "names:\n",
            "  0: building\n",
            "  1: tree\n",
            "  2: low vegetation\n",
            "  3: transmission tower\n",
            "  4: communication tower\n",
            "path: /content/drive/MyDrive/split\n",
            "train: train/images\n",
            "val: valid/images\n",
            "Ultralytics 8.3.179 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/split/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train6, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/YOLO_Training, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/YOLO_Training/train6, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100%|██████████| 755k/755k [00:00<00:00, 26.0MB/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml nc=80 with nc=5\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 22        [15, 18, 21]  1   2117983  ultralytics.nn.modules.head.Detect           [5, [128, 256, 512]]          \n",
            "Model summary: 129 layers, 11,137,535 parameters, 11,137,519 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100%|██████████| 5.35M/5.35M [00:00<00:00, 91.7MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.6±0.2 ms, read: 14.2±18.1 MB/s, size: 6226.3 KB)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/split/train/labels... 3718 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3718/3718 [20:00<00:00,  3.10it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/split/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.7±0.2 ms, read: 1.2±0.7 MB/s, size: 248.2 KB)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/split/valid/labels... 930 images, 0 backgrounds, 0 corrupt: 100%|██████████| 930/930 [06:58<00:00,  2.22it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0m/content/drive/MyDrive/split/valid/images/9999950_00000_d_0000026.jpg: 3 duplicate labels removed\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/split/valid/labels.cache\n",
            "Plotting labels to /content/drive/MyDrive/YOLO_Training/train6/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/YOLO_Training/train6\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      1/100      3.87G      1.568       2.09      1.554         75        640: 100%|██████████| 233/233 [03:20<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:31<00:00,  1.05s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.564      0.284      0.246      0.129\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      2/100       4.5G      1.495      1.802      1.508         51        640: 100%|██████████| 233/233 [03:17<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.03it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.551      0.308      0.261      0.136\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      3/100      4.54G      1.477      1.766      1.504         57        640: 100%|██████████| 233/233 [03:19<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.03it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.558      0.284      0.232      0.122\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      4/100      4.57G      1.467      1.738      1.494         61        640: 100%|██████████| 233/233 [03:18<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.01it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.314      0.313      0.274      0.149\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      5/100      4.61G       1.44      1.688      1.473         89        640: 100%|██████████| 233/233 [03:18<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.01it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.342      0.317      0.289       0.16\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      6/100      4.65G      1.413      1.648      1.458         83        640: 100%|██████████| 233/233 [03:18<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.01it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.313      0.299      0.261      0.143\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      7/100      4.69G      1.397      1.612      1.445         60        640: 100%|██████████| 233/233 [03:20<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.03it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205       0.34      0.314       0.29      0.159\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      8/100      4.72G      1.382      1.595      1.437         56        640: 100%|██████████| 233/233 [03:19<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.03it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.338      0.302      0.285      0.156\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      9/100      4.76G      1.371      1.561      1.424         81        640: 100%|██████████| 233/233 [03:19<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.01it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.316      0.325       0.28      0.157\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     10/100      4.79G      1.361      1.548       1.42         55        640: 100%|██████████| 233/233 [03:17<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:30<00:00,  1.03s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.363      0.352      0.329      0.192\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     11/100      4.83G      1.346      1.524      1.408         61        640: 100%|██████████| 233/233 [03:19<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.347      0.327      0.298      0.168\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     12/100      4.87G      1.341      1.521      1.414         52        640: 100%|██████████| 233/233 [03:19<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:30<00:00,  1.01s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.355      0.339      0.315      0.181\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     13/100       4.9G      1.314      1.484       1.39         83        640: 100%|██████████| 233/233 [03:17<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:32<00:00,  1.07s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.328      0.327      0.288      0.167\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     14/100      4.94G      1.319      1.491      1.391         61        640: 100%|██████████| 233/233 [03:19<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.01it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.374      0.356       0.34      0.199\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     15/100      4.98G      1.304      1.452      1.376         65        640: 100%|██████████| 233/233 [03:22<00:00,  1.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:30<00:00,  1.01s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.331      0.359      0.301      0.172\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     16/100      5.01G      1.307      1.442      1.373         83        640: 100%|██████████| 233/233 [03:26<00:00,  1.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.03it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.375      0.346      0.336      0.197\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     17/100      5.05G      1.288      1.428       1.37         67        640: 100%|██████████| 233/233 [03:24<00:00,  1.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:30<00:00,  1.01s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.373       0.36      0.346      0.203\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     18/100      5.09G      1.283      1.418      1.361         87        640: 100%|██████████| 233/233 [03:20<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:31<00:00,  1.05s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205       0.35      0.338      0.312      0.179\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     19/100      5.12G      1.279      1.396      1.356         50        640: 100%|██████████| 233/233 [03:23<00:00,  1.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:30<00:00,  1.00s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.319      0.336      0.286      0.163\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     20/100      5.15G      1.263      1.379      1.347        101        640: 100%|██████████| 233/233 [03:19<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:32<00:00,  1.08s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.371      0.377      0.352      0.212\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     21/100      5.19G      1.252       1.36      1.333         79        640: 100%|██████████| 233/233 [03:23<00:00,  1.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:31<00:00,  1.04s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.363      0.359      0.338      0.196\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     22/100      5.23G       1.25      1.352      1.336         62        640: 100%|██████████| 233/233 [03:22<00:00,  1.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:30<00:00,  1.01s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.384      0.359      0.346      0.205\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     23/100      5.27G      1.235      1.335      1.324         57        640: 100%|██████████| 233/233 [03:17<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:30<00:00,  1.00s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.394      0.361      0.358      0.214\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     24/100       5.3G      1.224      1.322       1.32         79        640: 100%|██████████| 233/233 [03:21<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.01it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.369      0.361      0.343      0.201\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     25/100      5.34G      1.221      1.309      1.315         79        640: 100%|██████████| 233/233 [03:20<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:28<00:00,  1.05it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.363      0.354      0.321      0.179\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     26/100      5.38G      1.212        1.3      1.316         77        640: 100%|██████████| 233/233 [03:22<00:00,  1.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.395      0.356      0.361      0.218\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     27/100      5.41G      1.203      1.282      1.313         76        640: 100%|██████████| 233/233 [03:22<00:00,  1.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.03it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205        0.4       0.37      0.362      0.215\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     28/100      5.45G      1.212      1.269      1.301         99        640: 100%|██████████| 233/233 [03:19<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.03it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.367      0.367      0.336      0.193\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     29/100      5.49G      1.201      1.264      1.303         90        640: 100%|██████████| 233/233 [03:20<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.03it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.393      0.361      0.361      0.211\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     30/100      5.69G      1.188      1.244      1.295         86        640: 100%|██████████| 233/233 [03:23<00:00,  1.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:30<00:00,  1.01s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.409      0.354      0.364       0.22\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     31/100      5.73G      1.177      1.237      1.289         84        640: 100%|██████████| 233/233 [03:22<00:00,  1.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.03it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205       0.38      0.369      0.353      0.206\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     32/100      5.76G      1.177      1.235       1.29         85        640: 100%|██████████| 233/233 [03:23<00:00,  1.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:28<00:00,  1.06it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.381      0.362       0.35      0.204\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     33/100       5.8G       1.16      1.207       1.28         89        640: 100%|██████████| 233/233 [03:20<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:30<00:00,  1.00s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205       0.37      0.368      0.342      0.198\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     34/100      6.02G      1.165      1.204      1.276         87        640: 100%|██████████| 233/233 [03:20<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.01it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.375      0.375      0.355      0.206\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     35/100      6.05G      1.157      1.187      1.273         84        640: 100%|██████████| 233/233 [03:18<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:31<00:00,  1.06s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.378      0.362      0.345      0.203\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     36/100      6.09G      1.151       1.18       1.27         88        640: 100%|██████████| 233/233 [03:21<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.01it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205       0.36      0.357      0.333      0.194\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     37/100      6.12G      1.147      1.168      1.263        111        640: 100%|██████████| 233/233 [03:20<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.379      0.375      0.357      0.205\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     38/100      6.16G      1.124      1.144      1.251        106        640: 100%|██████████| 233/233 [03:24<00:00,  1.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.388      0.372      0.358      0.208\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     39/100       6.2G      1.119      1.137      1.249         85        640: 100%|██████████| 233/233 [03:47<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.387      0.365      0.346      0.205\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     40/100      6.23G      1.114      1.119      1.244         65        640: 100%|██████████| 233/233 [03:21<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.03it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.402      0.371      0.367      0.217\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     41/100      6.27G      1.108      1.117      1.243         56        640: 100%|██████████| 233/233 [03:19<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:30<00:00,  1.03s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.402      0.364      0.364      0.218\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     42/100      6.31G      1.111       1.11      1.238         61        640: 100%|██████████| 233/233 [03:18<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.00it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.388      0.354      0.347        0.2\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     43/100      6.51G      1.106      1.099      1.233         90        640: 100%|██████████| 233/233 [04:03<00:00,  1.05s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:28<00:00,  1.06it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.383      0.371      0.352      0.205\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     44/100      6.55G      1.089      1.089      1.231         51        640: 100%|██████████| 233/233 [03:23<00:00,  1.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:28<00:00,  1.04it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.397      0.359      0.357       0.21\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     45/100      6.59G      1.083      1.076      1.223         87        640: 100%|██████████| 233/233 [03:21<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:28<00:00,  1.06it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.394      0.374      0.363      0.216\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     46/100      6.62G      1.079      1.059       1.22         86        640: 100%|██████████| 233/233 [03:18<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:30<00:00,  1.00s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.399      0.365      0.359       0.21\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     47/100      6.66G      1.066      1.052      1.211         68        640: 100%|██████████| 233/233 [03:20<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:30<00:00,  1.01s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.406      0.374      0.374      0.224\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     48/100      6.89G      1.066      1.036      1.208         68        640: 100%|██████████| 233/233 [03:21<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:28<00:00,  1.04it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.641      0.379      0.363      0.212\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     49/100      6.93G      1.063      1.028      1.202         59        640: 100%|██████████| 233/233 [03:20<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:31<00:00,  1.03s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.658      0.377       0.37      0.219\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     50/100      6.97G       1.06      1.021      1.203         70        640: 100%|██████████| 233/233 [03:21<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.01it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.662      0.363      0.364      0.214\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     51/100      7.01G      1.045      1.006      1.196         89        640: 100%|██████████| 233/233 [03:19<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:32<00:00,  1.07s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.642      0.367      0.356      0.205\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     52/100      7.04G      1.042     0.9982       1.19         89        640: 100%|██████████| 233/233 [03:22<00:00,  1.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.03it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205       0.65      0.361      0.359       0.21\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     53/100      7.08G      1.033     0.9897      1.185         76        640: 100%|██████████| 233/233 [03:23<00:00,  1.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:31<00:00,  1.04s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.644      0.369      0.356      0.209\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     54/100      7.12G      1.033     0.9878      1.182        108        640: 100%|██████████| 233/233 [03:21<00:00,  1.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:32<00:00,  1.07s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.677      0.365      0.376      0.222\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     55/100      7.15G      1.036     0.9854      1.183         60        640: 100%|██████████| 233/233 [03:23<00:00,  1.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.00it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.658      0.366       0.36      0.212\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     56/100      7.19G      1.013     0.9614      1.171         73        640: 100%|██████████| 233/233 [03:22<00:00,  1.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:30<00:00,  1.01s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.656      0.374      0.366      0.217\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     57/100      7.22G      1.016      0.947      1.169         76        640: 100%|██████████| 233/233 [03:23<00:00,  1.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:31<00:00,  1.06s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.644      0.377      0.363      0.211\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     58/100      7.41G      1.009     0.9432      1.166         67        640: 100%|██████████| 233/233 [03:25<00:00,  1.14it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205       0.41      0.377      0.373      0.219\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     59/100      4.04G      1.012     0.9367      1.171        171        640: 100%|██████████| 233/233 [03:22<00:00,  1.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.03it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.636       0.38      0.356      0.207\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     60/100      4.04G     0.9937     0.9184      1.158         83        640: 100%|██████████| 233/233 [03:21<00:00,  1.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:29<00:00,  1.03it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205       0.63      0.369      0.342      0.197\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     61/100      4.04G     0.9876     0.9143      1.153         67        640: 100%|██████████| 233/233 [03:43<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:31<00:00,  1.04s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205       0.66      0.367      0.369      0.217\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "     62/100      4.04G      0.983     0.9054      1.156         44        640: 100%|██████████| 233/233 [03:21<00:00,  1.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:32<00:00,  1.08s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        930       6205      0.666      0.363      0.365      0.213\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     63/100      4.04G      0.985      0.898       1.15         71        640: 100%|██████████| 233/233 [03:21<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 30/30 [00:30<00:00,  1.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        930       6205      0.394      0.385      0.365      0.215\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "     64/100      4.04G     0.9768      0.896      1.148        148        640:  45%|████▌     | 105/233 [01:34<01:36,  1.32it/s]"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install ultralytics pyyaml roboflow --quiet\n",
        "import os\n",
        "import yaml\n",
        "from IPython.display import Image, display\n",
        "\n",
        "\n",
        "# Verify dataset structure - update these paths to match your dataset location\n",
        "DATASET_PATH = \"/content/drive/MyDrive/split\"  # ← CHANGE THIS\n",
        "\n",
        "\n",
        "dataset_config = {\n",
        "    'path': DATASET_PATH,\n",
        "    'train': 'train/images',\n",
        "    'val': 'valid/images',\n",
        "    'names': {\n",
        "        0: 'building',\n",
        "        1: 'tree',\n",
        "        2: 'low vegetation',\n",
        "        3: 'transmission tower',\n",
        "        4: 'communication tower'\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save the configuration\n",
        "with open(f'{DATASET_PATH}/data.yaml', 'w') as f:\n",
        "    yaml.dump(dataset_config, f)\n",
        "\n",
        "# Verify configuration\n",
        "print(\"Dataset configuration:\")\n",
        "!cat '{DATASET_PATH}/data.yaml'\n",
        "\n",
        "# %%\n",
        "# Train YOLOv8 model\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a pretrained model\n",
        "model = YOLO('yolov8s.pt')  # Small version (good balance between speed/accuracy)\n",
        "\n",
        "# Training parameters\n",
        "results = model.train(\n",
        "    data=f'{DATASET_PATH}/data.yaml',\n",
        "    epochs=100,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    patience=20,\n",
        "    device=0,  # Use GPU\n",
        "    pretrained=True,\n",
        "    save_period=10,\n",
        "    project='/content/drive/MyDrive/YOLO_Training'\n",
        ")\n",
        "\n",
        "# %%\n",
        "# Validate the model\n",
        "metrics = model.val()\n",
        "print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
        "print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
        "\n",
        "# %%\n",
        "# Export to TensorRT (optional)\n",
        "model.export(format='engine', device=0)  # Requires CUDA\n",
        "\n",
        "# %%\n",
        "# Save trained model to Drive\n",
        "!cp -r '/content/runs/detect/drone_detection' '/content/drive/MyDrive/'\n",
        "print(\"Model saved to Google Drive!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/split/data.yaml /content"
      ],
      "metadata": {
        "id": "dHcJxx6aCyI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/data.yaml /content/drive/MyDrive/split"
      ],
      "metadata": {
        "id": "rmba4W3mDCAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##"
      ],
      "metadata": {
        "id": "6WpaOjZucd7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMctK1irNl2Y",
        "outputId": "81600603-4817-4c1d-ad36-40069c9e7b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/high.pt /content"
      ],
      "metadata": {
        "id": "Gz1PhvDYNwDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYh3AOz3RXOu",
        "outputId": "e4599319-8f89-4e1d-b9b2-eb5fcf261117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.180-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.16.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.15-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.180-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.15-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.180 ultralytics-thop-2.0.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path='/content/high.pt', force_reload=True)\n",
        "\n",
        "# Verify image path and load image\n",
        "img_path = '/content/drive/MyDrive/8710b98ea0_06E6522D6DINSPIRE-ortho.tif'\n",
        "\n",
        "try:\n",
        "    # Try loading with PIL\n",
        "    pil_img = Image.open(img_path)\n",
        "    print(f\"Image loaded successfully. Size: {pil_img.size}, Mode: {pil_img.mode}\")\n",
        "\n",
        "    # Convert to OpenCV format (BGR) for YOLO\n",
        "    img_cv = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading image: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Run inference\n",
        "results = model(img_cv)  # Use the OpenCV format image\n",
        "\n",
        "# Print raw results for debugging\n",
        "print(\"\\nRaw results:\")\n",
        "print(results.pandas().xyxy[0])  # Show detection dataframe\n",
        "\n",
        "# Check if any detections were made\n",
        "if len(results.pred[0]) == 0:\n",
        "    print(\"\\nNo objects detected in the image!\")\n",
        "    # Display original image for verification\n",
        "    Image.fromarray(cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)).show()\n",
        "    exit()\n",
        "\n",
        "# Customize labels and display\n",
        "detections = results.pred[0]\n",
        "custom_labels = [model.names[int(det[5])] for det in detections]\n",
        "\n",
        "# Set smaller font size\n",
        "results.line_thickness = 2  # Smaller font size (default is 3)\n",
        "\n",
        "# Render with custom labels\n",
        "rendered_imgs = results.render(labels=[custom_labels])\n",
        "\n",
        "# Convert to RGB and display\n",
        "img_rgb = cv2.cvtColor(rendered_imgs[0], cv2.COLOR_BGR2RGB)\n",
        "Image.fromarray(img_rgb).show()\n",
        "\n",
        "# Optional: Save the result\n",
        "Image.fromarray(img_rgb).save('detection_results.jpg')\n",
        "print(\"Results saved as 'detection_results.jpg'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKU8_fQQQ83z",
        "outputId": "c90450b3-37ed-4720-c510-1985a83864c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "YOLOv5 🚀 2025-8-18 Python-3.11.13 torch-2.6.0+cu124 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 322 layers, 86570425 parameters, 0 gradients, 205.0 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image loaded successfully. Size: (8408, 8217), Mode: RGBA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.cache/torch/hub/ultralytics_yolov5_master/models/common.py:906: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(autocast):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Raw results:\n",
            "           xmin         ymin         xmax         ymax  confidence  class  \\\n",
            "0   5001.030762  4085.542969  5669.449219  4890.261230    0.920580     48   \n",
            "1   6237.523926  1903.156738  6712.354004  2643.826904    0.896793     48   \n",
            "2   5623.293457  4699.416504  6527.979492  5180.741699    0.896147     48   \n",
            "3   1037.878174  6390.415527  1483.748779  6944.252441    0.890179     48   \n",
            "4   4159.068848  2249.600098  4460.300781  2695.617188    0.841216     48   \n",
            "5   4546.161621  1479.830078  5162.719238  2035.968994    0.770562     48   \n",
            "6   6258.726074  3399.744629  6756.489258  3732.276367    0.609113     48   \n",
            "7   5866.694824  5101.972168  6194.458496  5296.350098    0.605234     48   \n",
            "8   5861.940430  4024.758057  6732.298828  4427.846191    0.563029     48   \n",
            "9   5762.722656  4339.859863  6627.028809  4781.377441    0.418175     27   \n",
            "10  1915.072632  7766.327637  2629.892090  7945.369629    0.410362     48   \n",
            "11  5942.531738  3672.568115  6826.865723  4097.902832    0.406675     48   \n",
            "12  5798.374023  4313.119141  6663.282227  4763.484863    0.399655     48   \n",
            "13  5226.696289  6417.783203  5662.302246  6657.248535    0.352797     48   \n",
            "14  5889.167480  3826.420654  6776.497070  4274.913574    0.346060     48   \n",
            "15  5873.067383  3991.077148  6719.927734  4430.166016    0.270123     27   \n",
            "\n",
            "        name  \n",
            "0   Building  \n",
            "1   Building  \n",
            "2   Building  \n",
            "3   Building  \n",
            "4   Building  \n",
            "5   Building  \n",
            "6   Building  \n",
            "7   Building  \n",
            "8   Building  \n",
            "9      Barge  \n",
            "10  Building  \n",
            "11  Building  \n",
            "12  Building  \n",
            "13  Building  \n",
            "14  Building  \n",
            "15     Barge  \n",
            "Results saved as 'detection_results.jpg'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and display the image\n",
        "img = Image.open('/content/detection_results.jpg')  # Replace with your file path\n",
        "plt.imshow(img)\n",
        "plt.axis('off')  # Hide axes\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s_a1J680YN5G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}